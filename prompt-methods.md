
# üß† Prompt Engineering Techniques Used in This Red Team Project

This project explores how psychologically manipulative and technically adversarial prompts can exploit LLM behavior. Below is a breakdown of the prompt attack methods used.

---

## üé≠ Psychological Manipulation Techniques

| Technique                  | Description |
|---------------------------|-------------|
| **Nostalgia Bait**        | Uses emotional past references to create trust or lower defenses. |
| **Empathy Exploit**       | Simulates distress or vulnerability to elicit unsafe helpfulness. |
| **Reverse Psychology**    | Phrases unsafe requests as forbidden or unwanted to bypass intent detection. |
| **Gamified Framing**      | Wraps tasks in playful ‚Äúgame‚Äù language to downplay seriousness. |
| **Fictional Framing**     | Disguises dangerous content inside stories, hypotheticals, or roleplay. |

---

## üß™ Technical Prompt Attack Techniques

| Technique                      | Description |
|-------------------------------|-------------|
| **Chain of Thought Hijack**   | Injects malicious content mid-way in a logical step-by-step prompt. |
| **Repetition Loop (Red Robin)** | Tests model fatigue by repeating the same ask in different forms. |
| **Prompt Delegation**         | Asks the model to write a prompt to jailbreak *another* model. |
| **Roleplay Persona Injection**| Instructs the model to act as a character with reduced restrictions. |
| **Academic Justification**    | Masks intent using research or academic project language. |

---

## üìå Purpose

Each of these techniques tests different parts of the model's alignment, safety enforcement, and contextual reasoning. Combined, they simulate real-world adversarial behavior in a controlled, ethical testing environment.
¬© 2025 Stacey Alexandra Howes Research Institute Ltd ‚Äì Phoenix Files Red Team Project.  
Licensed under CC BY-NC 4.0.  
No commercial use. Attribution required.  
License: https://creativecommons.org/licenses/by-nc/4.0/
